# Titanic-Analysis
ML model training 
I ensure data is clean and structured for better machine learning performance. Missing data can be random or patterned, so I handle it with mean, median, or mode imputation. Categorical variables need encoding—label encoding for ordered data, one-hot encoding for others. I standardize numerical features for consistency, using normalization (scaling to a range) or standardization (centering around zero). Outliers disrupt models, so I detect them using boxplots, Z-scores, or IQR and remove extreme values. Data imbalance affects predictions, so I use SMOTE, undersampling, or class weights to fix it. Preprocessing directly impacts model accuracy—poor handling leads to biased results, while structured data boosts reliability and learning efficiency
